{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import time\n",
    "import numpy as np\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    device = 'CPU'\n",
    "    seed = 42\n",
    "    \n",
    "    # Input image size and batch size\n",
    "    img_size = [318, 216]\n",
    "    batch_size = 128\n",
    "    upsample_thr = 30 # min sample of each class (upsample)\n",
    "    cv_filter = True # always keeps low sample data in train\n",
    "    \n",
    "    # Audio duration, sample rate, and length\n",
    "    duration = 10 # second\n",
    "    sample_rate = 16000\n",
    "    audio_len = duration*sample_rate\n",
    "    \n",
    "    # STFT parameters\n",
    "    nfft = 1024\n",
    "    window = 1024\n",
    "    hop_length = 512\n",
    "    fmin = 20\n",
    "    fmax = 8000\n",
    "    normalize = True\n",
    "    nmels = 216\n",
    "    \n",
    "    # Inference batch size, test time augmentation, and drop remainder\n",
    "    infer_bs = 2\n",
    "    tta = 1\n",
    "    drop_remainder = True\n",
    "    \n",
    "    # Number of epochs, model name, and number of folds\n",
    "    epochs = 25\n",
    "    model_name = 'EfficientNetB1'\n",
    "    fsr = False # reduce stride of stem block\n",
    "    num_fold = 5\n",
    "    \n",
    "    # Selected folds for training and evaluation\n",
    "    selected_folds = [0]\n",
    "\n",
    "    # Pretraining, neck features, and final activation function\n",
    "    pretrain = 'imagenet'\n",
    "    neck_features = 0\n",
    "    final_act = 'softmax'\n",
    "    \n",
    "    # Learning rate, optimizer, and scheduler\n",
    "    lr = 1e-3\n",
    "    scheduler = 'cos'\n",
    "    optimizer = 'Adam' # AdamW, Adam\n",
    "    \n",
    "    # Loss function and label smoothing\n",
    "    loss = 'CCE' # BCE, CCE\n",
    "    label_smoothing = 0.05 # label smoothing\n",
    "    \n",
    "    # Data augmentation parameters\n",
    "    augment=True\n",
    "    spec_augment_prob = 0.60\n",
    "    \n",
    "    # Time Freq masking\n",
    "    freq_mask_prob=0.50\n",
    "    num_freq_masks=1\n",
    "    freq_mask_param=10\n",
    "    time_mask_prob=0.50\n",
    "    num_time_masks=2\n",
    "    time_mask_param=25\n",
    "\n",
    "    # Audio Augmentation Settings\n",
    "    audio_augment_prob = 0.5\n",
    "    \n",
    "    mixup_prob = 0.65\n",
    "    mixup_alpha = 0.5\n",
    "    \n",
    "    cutmix_prob = 0.65\n",
    "    cutmix_alpha = 2.5\n",
    "    \n",
    "    timeshift_prob = 0.0\n",
    "    \n",
    "    gn_prob = 0.35\n",
    "\n",
    "    class_names = sorted(set(os.listdir('/home/saarthak/Downloads/research/spectrogram dataset/train')))\n",
    "    num_classes = len(class_names)\n",
    "    class_labels = list(range(num_classes))\n",
    "    label2name = dict(zip(class_labels, class_names))\n",
    "    name2label = {v:k for k,v in label2name.items()}\n",
    "    \n",
    "    # Training Settings\n",
    "    target_col = ['target']\n",
    "    tab_cols = ['filename']\n",
    "    monitor = 'auc'\n",
    "    debug = True\n",
    "    verbose = 0\n",
    "\n",
    "\n",
    "    # PyAudio\n",
    "    chunk = 1024  # Samples to read per frame\n",
    "    format = pyaudio.paInt16  # Audio format\n",
    "    channels = 1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(N_CLASSES=264):\n",
    "    inp = tf.keras.layers.Input(shape=(318, 216, 3))\n",
    "#     x = tf.keras.layers.LayerNormalization(name='batch_norm')(inp)\n",
    "    x = tf.keras.layers.Conv2D(8, kernel_size=(7,7), activation='tanh', padding='same', name='conv2d_tanh')(inp)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_5')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=(2,2), activation='relu', padding='same', name='conv2d_relu_5')(x)\n",
    "    x = tf.keras.layers.Flatten(name='flatten')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', activity_regularizer=tf.keras.regularizers.l2(0.001), name='dense')(x)\n",
    "    \n",
    "    o = tf.keras.layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=o, name='2d_convolution')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=CFG.lr),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=CFG.label_smoothing), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 34 variables. \n"
     ]
    }
   ],
   "source": [
    "model.load_weights('/home/saarthak/Documents/birdclef23/2024-05-16__04-58-15/cp.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters for audio capture\n",
    "FORMAT = pyaudio.paInt16  # Audio format (16-bit resolution)\n",
    "CHANNELS = 1  # Number of channels (1 for mono, 2 for stereo)\n",
    "RATE = 16000  # Sample rate (samples per second)\n",
    "CHUNK = 1024  # Number of audio frames per buffer\n",
    "RECORD_SECONDS = 10  # Duration of each recording in seconds\n",
    "OUTPUT_FILENAME = \"output.wav\"  # Output filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_ops(audio, data):\n",
    "    bytes_wav = bytes()\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open('output.wav', 'wb') as wf:\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(data)\n",
    "    rate, data = wavfile.read(\"output.wav\")\n",
    "    reduced_noise = nr.reduce_noise(y=data, sr=rate)\n",
    "    wavfile.write(\"output.wav\", rate, reduced_noise)\n",
    "    return reduced_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spec2Img(spec, num_channels=3):\n",
    "    # If the original image has 1 channel, convert it to a 3 channel image by repeating the same image across channel axis\n",
    "    if num_channels > 1:\n",
    "        img = tf.tile(spec[..., tf.newaxis], [1, 1, num_channels])\n",
    "    else:\n",
    "        img = spec[..., tf.newaxis]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(audio):\n",
    "    spec = librosa.feature.melspectrogram(y=audio, sr=CFG.sample_rate, \n",
    "                                       n_mels=CFG.nmels,\n",
    "                                       n_fft=CFG.nfft,\n",
    "                                       hop_length=CFG.hop_length,\n",
    "                                       fmax=CFG.fmax,\n",
    "                                       fmin=CFG.fmin,\n",
    "                                       )\n",
    "    spec = librosa.power_to_db(spec, ref=np.max)\n",
    "    # print(spec.shape)\n",
    "    normalised_db = preprocessing.minmax_scale(spec)\n",
    "    return normalised_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def record_audio():\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Open stream\n",
    "    stream = audio.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Listening...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = np.frombuffer(stream.read(CHUNK))\n",
    "        if np.isnan(data).any():\n",
    "            data = np.nan_to_num(data)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Finished.\")\n",
    "    # # print(frames)\n",
    "    # print(type(frames[0]), frames[0].shape)\n",
    "\n",
    "    data = np.concatenate(frames)\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    \n",
    "    reduced_noise = wav_ops(audio, data)\n",
    "    reduced_noise = reduced_noise.astype('float32')\n",
    "    # reduced_noise = np.expand_dims(reduced_noise, axis=-1)\n",
    "    spec = get_melspectrogram(reduced_noise)\n",
    "    spec_tensor = tf.convert_to_tensor(spec)\n",
    "    spec_tensor = tf.transpose(spec_tensor)\n",
    "    spec_tensor = Spec2Img(spec_tensor)\n",
    "    spec_tensor = tf.image.resize_with_crop_or_pad(\n",
    "        spec_tensor, 318, 216\n",
    "    )\n",
    "    spec_tensor = tf.expand_dims(spec_tensor, axis = 0)\n",
    "    output = model.predict(spec_tensor)\n",
    "    print(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Finished.\n",
      "1/1 [==============================] - 1s 876ms/step\n",
      "[[8.64459260e-04 9.08913091e-03 2.86971510e-04 1.66294037e-03\n",
      "  1.38167001e-04 4.84880205e-04 8.24150105e-04 9.72185167e-04\n",
      "  4.31471213e-04 1.84404515e-02 6.91391295e-04 3.80631682e-05\n",
      "  1.37498864e-04 5.55342471e-04 4.88913711e-03 4.54133675e-02\n",
      "  4.46443853e-04 7.15099799e-04 5.30494493e-04 9.12372416e-05\n",
      "  5.79478918e-04 4.77342494e-03 1.14030023e-04 8.82263994e-05\n",
      "  2.93016341e-03 5.00452355e-04 1.03020291e-04 2.04454325e-02\n",
      "  1.98587566e-03 4.68381440e-05 1.22497911e-02 1.13026050e-04\n",
      "  5.19907662e-05 4.95412340e-03 1.74448434e-02 2.20477134e-02\n",
      "  4.72693355e-05 6.06958696e-04 4.06068470e-03 2.62921036e-04\n",
      "  7.38924777e-04 9.96794086e-03 1.22329472e-02 3.44861735e-04\n",
      "  3.82643455e-04 2.25974189e-04 3.11797230e-05 1.40886055e-04\n",
      "  8.35569855e-03 4.03604330e-03 2.00332855e-04 3.91955973e-06\n",
      "  9.83919366e-04 3.34785815e-04 3.98593947e-05 1.24758780e-02\n",
      "  1.12750125e-03 1.68467127e-03 2.87966104e-04 4.32427507e-03\n",
      "  8.88353406e-06 1.35275058e-03 2.73692273e-02 1.12295347e-04\n",
      "  2.12170766e-04 6.38775248e-03 1.31582632e-03 3.04448273e-04\n",
      "  2.50514247e-04 1.63957156e-05 7.27654085e-04 2.91655124e-05\n",
      "  6.36428245e-04 1.04924125e-04 3.39576363e-04 8.67689087e-05\n",
      "  9.51685885e-04 1.22964627e-03 1.36117460e-02 7.89577840e-04\n",
      "  1.79030714e-04 4.51363251e-03 2.67820014e-03 1.36296730e-03\n",
      "  1.00183199e-04 8.26359319e-04 2.13780859e-03 2.92439567e-04\n",
      "  1.66529827e-02 9.50303685e-04 1.34586496e-02 1.94153900e-03\n",
      "  2.00671115e-04 3.37259425e-03 7.09890519e-05 1.13280083e-03\n",
      "  1.21867852e-02 5.95686538e-03 4.72630927e-04 4.78293834e-04\n",
      "  6.12108051e-05 3.12487851e-03 3.22883745e-04 1.66126096e-03\n",
      "  4.92721982e-03 3.58366109e-02 2.79564480e-03 1.53482072e-02\n",
      "  2.81742751e-03 5.14261599e-04 8.21507187e-04 3.00628645e-03\n",
      "  4.58174822e-04 3.37529066e-03 3.10994219e-03 1.15967259e-05\n",
      "  3.62970936e-03 4.07384141e-05 3.50692756e-02 7.52314739e-03\n",
      "  1.18362159e-02 1.02879861e-02 1.21936377e-03 2.33786437e-03\n",
      "  1.13087612e-04 2.23201932e-03 1.11676764e-03 2.10256214e-04\n",
      "  7.29121151e-04 1.03616656e-03 3.42494622e-02 5.84550107e-05\n",
      "  5.74232370e-04 3.30465729e-03 4.60724899e-04 4.04881360e-03\n",
      "  6.20963983e-05 4.03978222e-04 9.10626040e-05 4.94472962e-03\n",
      "  1.35239257e-04 4.17646347e-03 4.08003943e-05 1.55311413e-04\n",
      "  1.31212451e-04 3.46887362e-04 3.46231624e-04 4.25634265e-04\n",
      "  2.06386903e-03 1.18918309e-04 1.58782976e-04 8.13135484e-05\n",
      "  3.57026700e-04 5.06342808e-03 6.81676902e-05 9.79713863e-04\n",
      "  1.05839781e-03 4.48162714e-03 2.47740478e-04 7.76537810e-04\n",
      "  2.96188839e-04 4.67917928e-03 5.75882557e-04 2.10399012e-04\n",
      "  7.89921614e-05 1.08385237e-03 1.96511101e-04 4.21045115e-04\n",
      "  2.61374778e-04 6.13518278e-05 1.10946910e-03 1.68722980e-02\n",
      "  2.75288336e-03 7.36379588e-04 4.60788637e-04 1.14672221e-02\n",
      "  1.14245818e-03 1.00694457e-03 4.63494740e-04 3.04259040e-04\n",
      "  2.39895118e-04 1.43002762e-04 2.68439035e-04 4.92796476e-04\n",
      "  4.72010230e-04 5.46635315e-02 2.49676610e-04 6.66879863e-03\n",
      "  5.29968813e-02 6.20697858e-04 6.69871224e-05 3.73589573e-04\n",
      "  3.33769189e-04 1.21070701e-03 4.65833837e-05 1.16397825e-03\n",
      "  4.37259674e-03 2.95789127e-04 8.79228767e-03 1.18033681e-03\n",
      "  1.36844363e-04 5.62294445e-04 4.72325191e-05 1.57435570e-04\n",
      "  4.64293826e-03 6.71124144e-04 2.04424700e-03 4.27441148e-04\n",
      "  8.40011425e-03 4.03539278e-04 1.55509205e-03 7.21709849e-03\n",
      "  2.07567168e-03 4.00550151e-03 2.78542342e-04 2.14386173e-03\n",
      "  1.30539003e-03 6.47144509e-04 1.34199872e-04 1.13185321e-03\n",
      "  3.33349686e-03 9.93242429e-05 6.45912588e-02 1.04758947e-04\n",
      "  4.17021057e-03 8.11759476e-03 1.52926391e-03 8.23442606e-05\n",
      "  1.10587263e-02 2.13971664e-03 1.02964612e-02 4.57420480e-03\n",
      "  3.56449527e-05 1.37483682e-02 1.19859969e-05 1.73791967e-04\n",
      "  8.42028763e-04 7.76786983e-05 1.09834655e-03 3.73902614e-03\n",
      "  5.48080316e-05 1.67244434e-04 7.04392372e-03 3.30571458e-03\n",
      "  4.75275301e-05 2.21260398e-05 4.51752509e-04 9.86361119e-05\n",
      "  2.51176674e-03 5.64808084e-04 6.61798520e-03 5.45043452e-03\n",
      "  9.28488225e-05 8.51374865e-03 2.76401348e-04 4.34911453e-05\n",
      "  5.60446060e-05 1.44595478e-03 4.59097140e-03 6.14342233e-03\n",
      "  8.10080860e-03 4.00063756e-04 8.01479723e-03 1.52139086e-03]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     record_audio()\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mRECORD_SECONDS\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait for the remaining time to make it 10 seconds total\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Main loop to record audio every 10 seconds\n",
    "while True:\n",
    "    record_audio()\n",
    "    time.sleep(20 - RECORD_SECONDS)  # Wait for the remaining time to make it 10 seconds total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
